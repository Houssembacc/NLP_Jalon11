{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Vectorisation et modelisation"
      ],
      "metadata": {
        "id": "dsh0207uVEhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "#import contractions\n",
        "\n",
        "\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sexC8CK_V6VV",
        "outputId": "d2080266-bffa-417d-872e-4034f051597b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CWQt3YPcVCA0"
      },
      "outputs": [],
      "source": [
        "DATASET_FILE = \"dataset_cleaned.csv\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_df = pd.read_csv(DATASET_FILE)\n",
        "dataset_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7tV5-GyuVwSG",
        "outputId": "a57d6010-11f6-4adf-c4f9-cb7fe2a1d3b0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  stars  length  \\\n",
              "0      I've only had food from here once and it wasn'...      1      68   \n",
              "1      I will never return here again.  Ever.  I was ...      1      87   \n",
              "2      I wish my experience was great as others. I di...      1     166   \n",
              "3      Are the rosemary grapefruit scones supposed to...      1      81   \n",
              "4      Our takeout order was half wrong. Food was mis...      1      32   \n",
              "...                                                  ...    ...     ...   \n",
              "24995  I was a loyal fan of Aroy before the ownership...      5      75   \n",
              "24996  Stopped here for a bite while wandering around...      5      55   \n",
              "24997  A quiet place with excellent food, great music...      5      32   \n",
              "24998  Super delicious food. Awesome vibe. I suffered...      5      41   \n",
              "24999  I have a lot of dietary restrictions and this ...      5      87   \n",
              "\n",
              "                                            text_cleaned  \n",
              "0      food memorable panang curry balance flavor lik...  \n",
              "1      NOT_return ever sit booth wait dinner come scu...  \n",
              "2      wish experience great others din wednesday nig...  \n",
              "3      rosemary grapefruit scone suppose taste like w...  \n",
              "4      takeout order half wrong food miss portion siz...  \n",
              "...                                                  ...  \n",
              "24995  loyal fan aroy ownership change apprehensive v...  \n",
              "24996  stopped bite wander around faneuil hall pleasa...  \n",
              "24997  quiet place excellent food great music helpful...  \n",
              "24998  super delicious food awesome vibe suffer disne...  \n",
              "24999  lot dietary restriction place spot superfood s...  \n",
              "\n",
              "[25000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72b46713-1628-4ddb-94ec-d7ce6425d897\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>stars</th>\n",
              "      <th>length</th>\n",
              "      <th>text_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I've only had food from here once and it wasn'...</td>\n",
              "      <td>1</td>\n",
              "      <td>68</td>\n",
              "      <td>food memorable panang curry balance flavor lik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I will never return here again.  Ever.  I was ...</td>\n",
              "      <td>1</td>\n",
              "      <td>87</td>\n",
              "      <td>NOT_return ever sit booth wait dinner come scu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I wish my experience was great as others. I di...</td>\n",
              "      <td>1</td>\n",
              "      <td>166</td>\n",
              "      <td>wish experience great others din wednesday nig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Are the rosemary grapefruit scones supposed to...</td>\n",
              "      <td>1</td>\n",
              "      <td>81</td>\n",
              "      <td>rosemary grapefruit scone suppose taste like w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Our takeout order was half wrong. Food was mis...</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>takeout order half wrong food miss portion siz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>I was a loyal fan of Aroy before the ownership...</td>\n",
              "      <td>5</td>\n",
              "      <td>75</td>\n",
              "      <td>loyal fan aroy ownership change apprehensive v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>Stopped here for a bite while wandering around...</td>\n",
              "      <td>5</td>\n",
              "      <td>55</td>\n",
              "      <td>stopped bite wander around faneuil hall pleasa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>A quiet place with excellent food, great music...</td>\n",
              "      <td>5</td>\n",
              "      <td>32</td>\n",
              "      <td>quiet place excellent food great music helpful...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>Super delicious food. Awesome vibe. I suffered...</td>\n",
              "      <td>5</td>\n",
              "      <td>41</td>\n",
              "      <td>super delicious food awesome vibe suffer disne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>I have a lot of dietary restrictions and this ...</td>\n",
              "      <td>5</td>\n",
              "      <td>87</td>\n",
              "      <td>lot dietary restriction place spot superfood s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72b46713-1628-4ddb-94ec-d7ce6425d897')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72b46713-1628-4ddb-94ec-d7ce6425d897 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72b46713-1628-4ddb-94ec-d7ce6425d897');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(ngram_range = (1,1), max_df = .75, min_df = .01) #un seuil minimale d'apparition de mots et maximale aussi\n",
        "df = dataset_df[dataset_df.stars<3]\n"
      ],
      "metadata": {
        "id": "8tl6b7q7V5O9"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = vectorizer.fit_transform(df.text_cleaned)\n",
        "feature_names = vectorizer.get_feature_names()\n",
        "#create a dense list\n",
        "print(X.shape)\n",
        "#print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZCHXsmVZZmr",
        "outputId": "82905246-6e76-43db-d2bb-2e7319ec3b6d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 868)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = TfidfVectorizer(ngram_range = (1,1), max_df = .7, min_df = .01)\n",
        "\n",
        "data_doc_mx = X.fit_transform(df.text_cleaned)\n",
        "\n",
        "data_dtm_text = pd.DataFrame(data_doc_mx.toarray(), columns=X.get_feature_names() )\n",
        "\n",
        "data_dtm_text.index = df.index\n",
        "#dataframe tf-idf\n",
        "#data_dtm_text\n",
        "# print(data_doc_mx)\n",
        "print(X)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg9HbLtIXOXB",
        "outputId": "e7e5677e-3466-4fe3-e7e7-d40789210be8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TfidfVectorizer(max_df=0.7, min_df=0.01)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### desplay les topic functions\n",
        "def display_topics(model, feature_names, num_top_words,topic_names=None):\n",
        "    # iterate through topics in topic-term matrix, 'H' aka\n",
        "    # model.components_\n",
        "    for ix, topic in enumerate(model.components_):\n",
        "        #print topic, topic number, and top words\n",
        "        if not topic_names or not topic_names[ix]:\n",
        "            print(\"\\nTopic \", ix)\n",
        "        else:\n",
        "            print(\"\\nTopic: '\",topic_names[ix],\"'\")\n",
        "        print(\", \".join([feature_names[i] \\\n",
        "             for i in topic.argsort()[:-num_top_words - 1:-1]]))"
      ],
      "metadata": {
        "id": "_zFeVidoXsny"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#run modeling on doc\n",
        "nmf_model = NMF(15)\n",
        "# Learn an NMF model for given Document Term Matrix 'V' \n",
        "# Extract the document-topic matrix 'W'\n",
        "doc_topic = nmf_model.fit_transform(data_dtm_text)\n",
        "# Extract top words from the topic-term matrix 'H' display_topics(nmf_model, tv_noun.get_feature_names(), 5)\n",
        "display_topics(nmf_model, X.get_feature_names(), 5)\n",
        "print(doc_topic)\n",
        "#print(nmf_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fygC-gGDbR4N",
        "outputId": "4f0296a6-eb0b-4fb8-957a-8cc7f2c07c5b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:294: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic  0\n",
            "say, customer, tell, call, manager\n",
            "\n",
            "Topic  1\n",
            "good, taste, like, dish, sauce\n",
            "\n",
            "Topic  2\n",
            "pizza, crust, cheese, topping, slice\n",
            "\n",
            "Topic  3\n",
            "order, take, delivery, get, wrong\n",
            "\n",
            "Topic  4\n",
            "food, service, bad, slow, good\n",
            "\n",
            "Topic  5\n",
            "table, come, server, waitress, ask\n",
            "\n",
            "Topic  6\n",
            "burger, fry, bun, onion, cheese\n",
            "\n",
            "Topic  7\n",
            "wait, minute, hour, 30, 15\n",
            "\n",
            "Topic  8\n",
            "chicken, rice, fry, wing, sauce\n",
            "\n",
            "Topic  9\n",
            "bar, drink, beer, bartender, night\n",
            "\n",
            "Topic  10\n",
            "time, last, first, location, second\n",
            "\n",
            "Topic  11\n",
            "place, like, really, get, look\n",
            "\n",
            "Topic  12\n",
            "sandwich, salad, cheese, bread, lettuce\n",
            "\n",
            "Topic  13\n",
            "sushi, roll, fish, rice, salmon\n",
            "\n",
            "Topic  14\n",
            "go, back, get, win, use\n",
            "[[0.         0.05879949 0.         ... 0.         0.         0.        ]\n",
            " [0.02979008 0.         0.         ... 0.00385666 0.         0.00222462]\n",
            " [0.01022991 0.03024781 0.         ... 0.         0.00535871 0.0243388 ]\n",
            " ...\n",
            " [0.03352691 0.0532386  0.         ... 0.         0.         0.00467798]\n",
            " [0.         0.03897179 0.01010715 ... 0.04128554 0.         0.02423754]\n",
            " [0.         0.01885039 0.         ... 0.         0.         0.02438866]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:1641: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.get_feature_names())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZhnxIWPbtIg",
        "outputId": "5e2f59b7-a332-4b56-99fb-97ad761a3fcc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['00', '10', '100', '11', '12', '15', '18', '20', '25', '30', '40', '45', '50', 'able', 'absolutely', 'acknowledge', 'across', 'act', 'actual', 'actually', 'add', 'afternoon', 'ago', 'agree', 'ahead', 'allow', 'almost', 'alone', 'along', 'already', 'alright', 'also', 'although', 'always', 'amaze', 'amazing', 'ambiance', 'amount', 'annoy', 'another', 'answer', 'anymore', 'anyone', 'anything', 'anyway', 'anywhere', 'apologize', 'apparently', 'appear', 'appetizer', 'appreciate', 'area', 'around', 'arrive', 'asian', 'ask', 'assume', 'atmosphere', 'attempt', 'attention', 'attentive', 'attitude', 'austin', 'available', 'average', 'avoid', 'away', 'awesome', 'awful', 'back', 'bacon', 'bad', 'bag', 'bar', 'bartender', 'base', 'basic', 'basically', 'bathroom', 'bbq', 'bean', 'beautiful', 'become', 'beef', 'beer', 'begin', 'behind', 'believe', 'best', 'beyond', 'big', 'bill', 'birthday', 'bit', 'bite', 'black', 'bland', 'block', 'booth', 'boston', 'bother', 'bottle', 'bottom', 'bowl', 'box', 'boyfriend', 'bread', 'break', 'breakfast', 'bring', 'broth', 'brown', 'brunch', 'buck', 'buffet', 'bun', 'burger', 'burn', 'burnt', 'burrito', 'business', 'busy', 'butter', 'buy', 'cafe', 'cake', 'calamari', 'call', 'came', 'car', 'card', 'care', 'case', 'cash', 'cashier', 'catch', 'certainly', 'chain', 'chair', 'chance', 'change', 'charge', 'cheap', 'check', 'cheese', 'chef', 'chewy', 'chicken', 'child', 'chinese', 'chip', 'chocolate', 'choice', 'choose', 'city', 'clean', 'clear', 'clearly', 'close', 'cocktail', 'coffee', 'cold', 'combo', 'come', 'comment', 'company', 'compare', 'complain', 'complete', 'completely', 'consider', 'contact', 'continue', 'conversation', 'cook', 'cooked', 'cool', 'corn', 'corner', 'correct', 'cost', 'could', 'counter', 'couple', 'course', 'cover', 'crab', 'cream', 'credit', 'crowd', 'crust', 'cup', 'curry', 'customer', 'cut', 'dark', 'date', 'daughter', 'day', 'deal', 'decent', 'decide', 'decor', 'definitely', 'delicious', 'deliver', 'delivery', 'desk', 'despite', 'dessert', 'different', 'din', 'diner', 'dining', 'dinner', 'dip', 'dirty', 'disappoint', 'disappointed', 'disappointing', 'disappointment', 'disgust', 'dish', 'dog', 'dollar', 'door', 'double', 'doubt', 'dress', 'drink', 'drive', 'drop', 'dry', 'due', 'early', 'easy', 'eat', 'egg', 'either', 'else', 'elsewhere', 'employee', 'empty', 'end', 'enjoy', 'enough', 'entire', 'entree', 'especially', 'establishment', 'etc', 'even', 'evening', 'ever', 'every', 'everyone', 'everything', 'excellent', 'except', 'excite', 'excuse', 'expect', 'expectation', 'expensive', 'experience', 'explain', 'extra', 'extremely', 'eye', 'face', 'fact', 'fail', 'fair', 'fairly', 'fall', 'family', 'fan', 'far', 'fast', 'favorite', 'feel', 'felt', 'figure', 'fill', 'finally', 'find', 'fine', 'finish', 'first', 'fish', 'five', 'fix', 'flag', 'flat', 'flavor', 'flavorless', 'floor', 'follow', 'food', 'foot', 'forever', 'forget', 'forward', 'four', 'free', 'french', 'fresh', 'friday', 'fried', 'friend', 'friendly', 'front', 'frozen', 'fry', 'full', 'fun', 'game', 'garlic', 'general', 'get', 'girl', 'girlfriend', 'give', 'glass', 'go', 'god', 'good', 'got', 'grab', 'greasy', 'great', 'green', 'greet', 'grill', 'grilled', 'gross', 'group', 'guess', 'guest', 'guy', 'hair', 'half', 'hand', 'handle', 'hang', 'happen', 'happy', 'hard', 'hate', 'head', 'hear', 'hell', 'help', 'high', 'highly', 'hit', 'hold', 'home', 'honestly', 'hop', 'hope', 'horrible', 'host', 'hostess', 'hot', 'hotel', 'hour', 'house', 'however', 'huge', 'hungry', 'husband', 'ice', 'ignore', 'immediately', 'include', 'incredibly', 'indian', 'inedible', 'inform', 'ingredient', 'inside', 'instead', 'issue', 'italian', 'item', 'job', 'joint', 'keep', 'kid', 'kind', 'kitchen', 'know', 'lack', 'lady', 'lamb', 'large', 'last', 'late', 'later', 'learn', 'least', 'leave', 'less', 'let', 'lettuce', 'level', 'life', 'light', 'like', 'line', 'list', 'literally', 'little', 'live', 'lobster', 'local', 'location', 'long', 'look', 'lose', 'lot', 'loud', 'love', 'low', 'lunch', 'mac', 'main', 'make', 'man', 'manage', 'management', 'manager', 'many', 'margarita', 'matter', 'may', 'maybe', 'meal', 'mean', 'meat', 'mediocre', 'medium', 'meet', 'meh', 'mention', 'menu', 'mess', 'mexican', 'middle', 'might', 'min', 'mind', 'mine', 'minute', 'miss', 'mistake', 'mix', 'mixed', 'money', 'month', 'morning', 'mostly', 'mouth', 'move', 'much', 'multiple', 'mushroom', 'music', 'must', 'name', 'napkin', 'nasty', 'near', 'nearby', 'nearly', 'need', 'needless', 'negative', 'neighborhood', 'neither', 'new', 'next', 'nice', 'night', 'non', 'none', 'noodle', 'normal', 'normally', 'not_a', 'not_again', 'not_be', 'not_come', 'not_do', 'not_eat', 'not_even', 'not_flavor', 'not_get', 'not_go', 'not_good', 'not_great', 'not_have', 'not_know', 'not_like', 'not_one', 'not_only', 'not_order', 'not_recommend', 'not_return', 'not_so', 'not_sure', 'not_that', 'not_the', 'not_to', 'not_very', 'not_worth', 'note', 'nothing', 'notice', 'number', 'obviously', 'odd', 'offer', 'often', 'oh', 'oil', 'ok', 'okay', 'old', 'one', 'onion', 'online', 'open', 'opinion', 'option', 'order', 'ordered', 'others', 'otherwise', 'outside', 'overall', 'overcook', 'overprice', 'overpriced', 'owner', 'pack', 'par', 'park', 'parking', 'part', 'party', 'pass', 'past', 'pasta', 'patio', 'patron', 'pay', 'people', 'pepper', 'per', 'perhaps', 'person', 'phone', 'pick', 'picture', 'pie', 'piece', 'pizza', 'place', 'plain', 'plan', 'plastic', 'plate', 'play', 'pleasant', 'please', 'plenty', 'plus', 'pm', 'point', 'poor', 'poorly', 'pork', 'portion', 'portland', 'positive', 'post', 'pot', 'potato', 'pour', 'prepare', 'pretty', 'previous', 'price', 'probably', 'problem', 'proceed', 'provide', 'pull', 'put', 'quality', 'question', 'quick', 'quickly', 'quite', 'rare', 'rather', 'rating', 'raw', 'read', 'ready', 'real', 'realize', 'really', 'reason', 'receipt', 'receive', 'recently', 'recommend', 'red', 'refill', 'refund', 'refuse', 'register', 'regular', 'remember', 'remind', 'request', 'reservation', 'response', 'rest', 'restaurant', 'return', 'review', 'rib', 'rice', 'ridiculous', 'right', 'ring', 'roll', 'room', 'round', 'rude', 'ruin', 'run', 'rush', 'sad', 'sadly', 'salad', 'salmon', 'salsa', 'salt', 'salty', 'sandwich', 'saturday', 'sauce', 'sausage', 'save', 'saw', 'say', 'screw', 'seafood', 'season', 'seat', 'seating', 'second', 'see', 'seem', 'selection', 'sell', 'send', 'seriously', 'serve', 'server', 'service', 'set', 'several', 'shame', 'share', 'shock', 'shop', 'short', 'shot', 'show', 'shrimp', 'sick', 'side', 'sign', 'similar', 'simple', 'simply', 'since', 'single', 'sit', 'situation', 'size', 'skip', 'slice', 'slightly', 'slow', 'small', 'smell', 'smile', 'soft', 'soggy', 'someone', 'something', 'sometimes', 'somewhere', 'son', 'soon', 'sorry', 'sort', 'sound', 'soup', 'sour', 'space', 'speak', 'special', 'spend', 'spice', 'spicy', 'spinach', 'spot', 'staff', 'stale', 'stand', 'standard', 'star', 'start', 'state', 'stay', 'steak', 'step', 'stick', 'still', 'stomach', 'stop', 'store', 'story', 'strange', 'street', 'stuff', 'style', 'sub', 'suck', 'suggest', 'sunday', 'super', 'suppose', 'sure', 'surprise', 'sushi', 'sweet', 'table', 'taco', 'take', 'takeout', 'talk', 'taste', 'tasteless', 'tasty', 'tea', 'tell', 'ten', 'tender', 'terrible', 'texture', 'thai', 'thank', 'thanks', 'thick', 'thin', 'thing', 'think', 'third', 'though', 'three', 'throw', 'time', 'tiny', 'tip', 'toast', 'today', 'together', 'tomato', 'tonight', 'top', 'topping', 'tortilla', 'total', 'totally', 'touch', 'tough', 'town', 'treat', 'trip', 'try', 'turn', 'twice', 'two', 'type', 'undercooked', 'understand', 'unfortunately', 'unless', 'update', 'upon', 'use', 'usually', 'value', 'vegetable', 'vegetarian', 'veggie', 'view', 'visit', 'wait', 'waited', 'waiter', 'waitress', 'walk', 'wall', 'want', 'warm', 'waste', 'watch', 'water', 'way', 'week', 'weekend', 'weird', 'well', 'went', 'whatever', 'white', 'whole', 'wife', 'win', 'window', 'wine', 'wing', 'wish', 'within', 'without', 'woman', 'wonder', 'wonderful', 'word', 'work', 'worker', 'world', 'worst', 'worth', 'would', 'wow', 'wrap', 'write', 'wrong', 'yeah', 'year', 'yell', 'yelp', 'yes', 'yesterday', 'yet', 'young', 'zero']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "liste=[]\n",
        "for i in range(15):\n",
        "  var='topic_'+str(i)\n",
        "  liste.append(var)\n",
        "liste\n",
        "df_topic = pandas.DataFrame(doc_topic, columns=liste)\n",
        "df_topic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "eLGp8XE_ikb-",
        "outputId": "350f7cac-44c8-41ec-c95b-2f2a29020da0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       topic_0   topic_1   topic_2   topic_3   topic_4   topic_5   topic_6  \\\n",
              "0     0.000000  0.058799  0.000000  0.000000  0.035946  0.000000  0.001182   \n",
              "1     0.029790  0.000000  0.000000  0.000000  0.000000  0.025245  0.000000   \n",
              "2     0.010230  0.030248  0.000000  0.003348  0.016546  0.025477  0.000000   \n",
              "3     0.002830  0.056264  0.000236  0.000000  0.000000  0.016779  0.000676   \n",
              "4     0.000000  0.007107  0.000000  0.052765  0.017127  0.000000  0.000000   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9995  0.000000  0.033942  0.000540  0.003527  0.000000  0.000000  0.000000   \n",
              "9996  0.015259  0.055137  0.064008  0.008559  0.000000  0.001732  0.001758   \n",
              "9997  0.033527  0.053239  0.000000  0.036482  0.021420  0.036079  0.000591   \n",
              "9998  0.000000  0.038972  0.010107  0.000000  0.016521  0.000000  0.000000   \n",
              "9999  0.000000  0.018850  0.000000  0.002708  0.013700  0.040729  0.000000   \n",
              "\n",
              "       topic_7   topic_8   topic_9  topic_10  topic_11  topic_12  topic_13  \\\n",
              "0     0.000000  0.010638  0.000000  0.000000  0.029057  0.000000  0.000000   \n",
              "1     0.025224  0.000475  0.004546  0.000000  0.000000  0.003857  0.000000   \n",
              "2     0.000000  0.057128  0.025369  0.003229  0.000000  0.000000  0.005359   \n",
              "3     0.000000  0.000000  0.006419  0.007872  0.021620  0.000000  0.000000   \n",
              "4     0.016625  0.000580  0.001213  0.000000  0.032342  0.003753  0.000472   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "9995  0.000000  0.002721  0.000000  0.000000  0.000000  0.003701  0.000000   \n",
              "9996  0.000000  0.006819  0.000000  0.014767  0.043749  0.055308  0.000000   \n",
              "9997  0.000000  0.000000  0.017488  0.003705  0.000000  0.000000  0.000000   \n",
              "9998  0.000000  0.001952  0.000000  0.000000  0.000000  0.041286  0.000000   \n",
              "9999  0.000000  0.000000  0.000000  0.105051  0.000000  0.000000  0.000000   \n",
              "\n",
              "      topic_14  \n",
              "0     0.000000  \n",
              "1     0.002225  \n",
              "2     0.024339  \n",
              "3     0.020332  \n",
              "4     0.000000  \n",
              "...        ...  \n",
              "9995  0.000000  \n",
              "9996  0.011877  \n",
              "9997  0.004678  \n",
              "9998  0.024238  \n",
              "9999  0.024389  \n",
              "\n",
              "[10000 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6323b179-72ec-4165-8a6e-b7911d6534e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>topic_0</th>\n",
              "      <th>topic_1</th>\n",
              "      <th>topic_2</th>\n",
              "      <th>topic_3</th>\n",
              "      <th>topic_4</th>\n",
              "      <th>topic_5</th>\n",
              "      <th>topic_6</th>\n",
              "      <th>topic_7</th>\n",
              "      <th>topic_8</th>\n",
              "      <th>topic_9</th>\n",
              "      <th>topic_10</th>\n",
              "      <th>topic_11</th>\n",
              "      <th>topic_12</th>\n",
              "      <th>topic_13</th>\n",
              "      <th>topic_14</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.058799</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.035946</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001182</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010638</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029057</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.029790</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025245</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.025224</td>\n",
              "      <td>0.000475</td>\n",
              "      <td>0.004546</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.010230</td>\n",
              "      <td>0.030248</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003348</td>\n",
              "      <td>0.016546</td>\n",
              "      <td>0.025477</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.057128</td>\n",
              "      <td>0.025369</td>\n",
              "      <td>0.003229</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005359</td>\n",
              "      <td>0.024339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.002830</td>\n",
              "      <td>0.056264</td>\n",
              "      <td>0.000236</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016779</td>\n",
              "      <td>0.000676</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006419</td>\n",
              "      <td>0.007872</td>\n",
              "      <td>0.021620</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.052765</td>\n",
              "      <td>0.017127</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016625</td>\n",
              "      <td>0.000580</td>\n",
              "      <td>0.001213</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.032342</td>\n",
              "      <td>0.003753</td>\n",
              "      <td>0.000472</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.033942</td>\n",
              "      <td>0.000540</td>\n",
              "      <td>0.003527</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002721</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003701</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0.015259</td>\n",
              "      <td>0.055137</td>\n",
              "      <td>0.064008</td>\n",
              "      <td>0.008559</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001732</td>\n",
              "      <td>0.001758</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006819</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014767</td>\n",
              "      <td>0.043749</td>\n",
              "      <td>0.055308</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0.033527</td>\n",
              "      <td>0.053239</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.036482</td>\n",
              "      <td>0.021420</td>\n",
              "      <td>0.036079</td>\n",
              "      <td>0.000591</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017488</td>\n",
              "      <td>0.003705</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038972</td>\n",
              "      <td>0.010107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016521</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001952</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.041286</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018850</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002708</td>\n",
              "      <td>0.013700</td>\n",
              "      <td>0.040729</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.105051</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.024389</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6323b179-72ec-4165-8a6e-b7911d6534e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6323b179-72ec-4165-8a6e-b7911d6534e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6323b179-72ec-4165-8a6e-b7911d6534e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#prendre le coef max pour chaque review lié à un topic\n",
        "liste=[]\n",
        "for i in df_topic.columns:\n",
        "  data_f=df_topic.sort_values(by=i, ascending=False)\n",
        "  liste.append(data_f.index[:2].to_list())\n",
        "print(liste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEJCtUQfoAnN",
        "outputId": "90085c35-77ab-4644-b194-5de38f8c81ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1510, 278], [9098, 5043], [5484, 6518], [6369, 4146], [375, 6301], [9601, 6166], [6270, 7346], [5558, 4098], [9130, 1114], [5669, 9897], [9983, 7517], [920, 2490], [6384, 7258], [6286, 9041], [4079, 463]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AtZXCcUE1X61"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_6=pandas.DataFrame(doc_topic)\n",
        "dict={}\n",
        "for i in range(15):\n",
        "  top_2=df_6.nlargest(2,i,keep='all')\n",
        "  top2_indexes=top_2[0].keys().to_list()\n",
        "  dict[i]=df['text'][top2_indexes].to_list()\n",
        "df_corr=pandas.DataFrame(dict)\n",
        "df_corr\n",
        "print(dict.get(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqa8NiacwKjg",
        "outputId": "61bc149e-653c-4da5-c9f6-517b91f6d9b9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Unos is actually my favorite restaurant and yet it\\'s come to this--a two star review.  This particular Unos I\\'ve been to more times than I can count and I\\'ve had at least 3 other bad customer service experiences, but the one I had tonight takes the cake.  The guy I had twice before was so negligent that I got his name from my check and memorized it so that when I returned I\\'d ask that they seat me anywhere but his area.\\n\\nI came in today and asked for a one person booth for one and she says they don\\'t have any so they had to seat me in the back where all the tables are.  Ok, no real problem, but I was there alone, and it wasn\\'t peak hours just yet; it was obvious that I just wanted to eat and enjoy a meal with minimal disturbance or distraction.  And yet, she tried to seat me DIRECTLY next to another person at a table, even though the whole space where the tables were was empty.  I said no, I\\'d like to sit over there please (referring to a small table on the other side) and she obliged.  It just seemed like common sense and common courtesy to me.  Even in mall foodcourts, total strangers don\\'t sit directly next to one another, let alone at an uncrowded sit-down restaurant.  \\n\\nThen, maybe 10 minutes later, they came back and seated a party of two DIRECTLY next to me.  It was extremely awkward because the rest of the area was just about empty and fairly quiet, and they were so close to me.  I was irritated; she easily could have sat them at any other of the 5 empty tables and the waitress assigned to that area wouldn\\'t have been inconvenienced.  I was going to try to tough it out, but the woman at the table turned out to be particularly loud, borderline obnoxious in my opinion.  I put on my headphones (not earbuds, but headphones) to drown her out, even though I\\'d intended specifically to come there to read while I ate dinner.  Could still hear her loud and clear.  I tactfully asked the waitress if they had a table available up front, and she responds, \"no, they\\'re all taken.  I can serve you here\" pointing to the table 4 inches to my right.  I responded \"No, that would be the same thing\", trying to maintain my tone of voice.  And though my request to be moved was clearly code for \"get me out of here please! NOW.\", she wouldn\\'t oblige.  They lied.  There were tables available.  I discovered this when, only moments after they brought out my order, I quickly gathered all of my uneaten food and was walking out to leave with it.  They just didn\\'t want to move me because of the inconvenience of either having to switch me to another waiter, or her having to serve me outside of her table area. \\n\\nMy whole issue really is that they don\\'t seem customer service centered and reading some of the other reviews, they don\\'t make common sense decisions with their customers.  3 distinct times I\\'ve walked out of there in a huff because of the treatment.  I also agree with some of the other reviewers, they tend to take a little too long, even when it\\'s not crowded.  I wouldn\\'t recommend this location at all just because the service is too much of a gamble, you never know what you\\'re gonna get.  To be fair, the food is consistent and I have had some really good waiters here and there, but again, it\\'s too much of a gamble.', \"If you can get take out, I highly recommend it.  food is great, service is not.  Torn between 2 stars and 3 because the service totally just killed it for me.  \\n\\nThe restaurant is not that big and there are a few tables actually outside of the restaurant in the adjoining building (very random).  Luckily our table got to sit outside in this adjacent building. \\n\\nService was TERRIBLE.  We had 8pm reservations and when we got there, there was no host and we stood there for a few minutes before someone acknowledged us.  We then proceeded to say who the reservation was under (mind you, we see it on the computer screen) and he looks blankly at the computer screen.  We had to point it out to him.  We are seated and we don't have a waiter come by for 25 minutes to even greet us or ask us if we want anything to drink.  We order probably 30 minutes after being seated and then our food comes out after another 40 minute wait.  No one comes by our table until it's time to clear our plates.  They then drop a dessert menu on our table and never returned.  We would probably be sitting there if we didn't get up to ask for the check. There was a larger function going on in the back room, but that's still no excuse for poor service.  By the end of the night when they dropped the dessert menu off the only parties left were the function in the back, our table, and 4 other tables.\\n\\nMy table shared 3 pizzas and gnocchi.   I would highly recommend any of the pizzas.. I couldn't decide which one I liked the most.  Gnocchi was nice and light and everyone seemed to enjoy it (it's spinach gnocchi so it's green, don't let the color weird you out)\\n\\nI probably won't go again to have a sit down dinner, but would consider placing a take out order for a pizza again.\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Interpretation de Topic"
      ],
      "metadata": {
        "id": "-0gbSMHJ4733"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interpretation_topi={\n",
        "    'topic0' : 'TICKET PAYEMENT',\n",
        "    'topic1' : 'OVERLOADED RESTAURANT',\n",
        "    'topic2' : 'PIZZA/DELIVERY',\n",
        "    'topic3' : 'PRICES/ONLINE-ORDERING',\n",
        "    'topic4' : 'FOOD/SERVICE',\n",
        "    'topic5' : 'TABLE/BOTHERING',\n",
        "    'topic6' : 'SERVICE',\n",
        "    'topic7' : 'TEMPS D ATTENTE',\n",
        "    'topic8' : 'CHICKEN',\n",
        "    'topic9' : 'BEER/BAR',\n",
        "    'topic10' : 'BAD PLACE TO EAT',\n",
        "    'topic11' : 'SUSHI',\n",
        "    'topic12' : 'LUNCH/SANDWICH',\n",
        "    'topic13' : 'AMBIANCE',\n",
        "    'topic14' : 'WAITER'\n",
        "}"
      ],
      "metadata": {
        "id": "DrQL_czf5RGE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fichier Pickle Vectoriseur"
      ],
      "metadata": {
        "id": "OEQaPnn5tgF5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('vectorizer.bin', 'wb') as fichier:\n",
        "  pickle.dump(X, fichier, pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "NE_epUxiqM02"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fichier Pickle Modèle"
      ],
      "metadata": {
        "id": "A6Hhz__6vX_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('model_nmf.bin', 'wb') as fichier:\n",
        "  pickle.dump(nmf_model, fichier, pickle.HIGHEST_PROTOCOL)\n"
      ],
      "metadata": {
        "id": "PA_wfK0luEgQ"
      },
      "execution_count": 25,
      "outputs": []
    }
  ]
}